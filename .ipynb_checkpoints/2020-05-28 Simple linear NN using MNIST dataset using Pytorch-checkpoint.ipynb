{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_classify(img, ps, version=\"MNIST\"):\n",
    "    ''' Function for viewing an image and it's predicted classes.\n",
    "    '''\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    if version == \"MNIST\":\n",
    "        ax2.set_yticklabels(np.arange(10))\n",
    "    elif version == \"Fashion\":\n",
    "        ax2.set_yticklabels(['T-shirt/top',\n",
    "                            'Trouser',\n",
    "                            'Pullover',\n",
    "                            'Dress',\n",
    "                            'Coat',\n",
    "                            'Sandal',\n",
    "                            'Shirt',\n",
    "                            'Sneaker',\n",
    "                            'Bag',\n",
    "                            'Ankle Boot'], size='small');\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transform of MNIST data\n",
    "transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                transforms.Normalize((0.5, ), (0.5, )), ]) # Normalize to mean=0.5, std=0.5\n",
    "\n",
    "# Download and load data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3153, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Build a naive feedforward model\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128, 64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64, 10))\n",
    "\n",
    "# We use cross-entropy as our loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Get batch of data to try\n",
    "images, labels = next(iter(dataloader))\n",
    "# Flatten images to 784-feature vector\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# forward pass to get logits\n",
    "logits = model(images)\n",
    "# Calculate the loss\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Negative Log Likelihood loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2863, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128, 64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64, 10),\n",
    "                     nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(dataloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "logits = model(images)\n",
    "loss = criterion(logits, labels)\n",
    "print(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward pass using autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[-0.0021, -0.0021, -0.0021,  ..., -0.0021, -0.0021, -0.0021],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0042,  0.0042,  0.0042,  ...,  0.0042,  0.0042,  0.0042],\n",
      "        ...,\n",
      "        [ 0.0018,  0.0018,  0.0018,  ...,  0.0018,  0.0018,  0.0018],\n",
      "        [ 0.0014,  0.0014,  0.0014,  ...,  0.0014,  0.0014,  0.0014],\n",
      "        [ 0.0010,  0.0010,  0.0010,  ...,  0.0010,  0.0010,  0.0010]])\n"
     ]
    }
   ],
   "source": [
    "print ('Before backward pass: \\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print ('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Stochastic Gradient Decent for a single step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights:\n",
      " Parameter containing:\n",
      "tensor([[-0.0257, -0.0198, -0.0302,  ...,  0.0124, -0.0321, -0.0010],\n",
      "        [ 0.0221, -0.0200,  0.0132,  ..., -0.0175, -0.0061,  0.0282],\n",
      "        [-0.0066, -0.0285,  0.0130,  ...,  0.0169, -0.0014,  0.0171],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0043, -0.0219,  ...,  0.0072,  0.0124,  0.0140],\n",
      "        [-0.0070,  0.0121, -0.0148,  ...,  0.0128, -0.0043, -0.0094],\n",
      "        [-0.0171,  0.0036,  0.0092,  ...,  0.0018, -0.0247, -0.0164]],\n",
      "       requires_grad=True)\n",
      "Gradient - tensor([[0.0042, 0.0042, 0.0042,  ..., 0.0042, 0.0042, 0.0042],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0069, 0.0069, 0.0069,  ..., 0.0069, 0.0069, 0.0069],\n",
      "        ...,\n",
      "        [0.0009, 0.0009, 0.0009,  ..., 0.0009, 0.0009, 0.0009],\n",
      "        [0.0026, 0.0026, 0.0026,  ..., 0.0026, 0.0026, 0.0026],\n",
      "        [0.0012, 0.0012, 0.0012,  ..., 0.0012, 0.0012, 0.0012]])\n",
      "Updated weights:\n",
      " Parameter containing:\n",
      "tensor([[-0.0257, -0.0198, -0.0302,  ...,  0.0124, -0.0322, -0.0010],\n",
      "        [ 0.0221, -0.0200,  0.0132,  ..., -0.0175, -0.0061,  0.0282],\n",
      "        [-0.0067, -0.0286,  0.0130,  ...,  0.0168, -0.0014,  0.0171],\n",
      "        ...,\n",
      "        [ 0.0185, -0.0043, -0.0219,  ...,  0.0072,  0.0124,  0.0140],\n",
      "        [-0.0070,  0.0120, -0.0148,  ...,  0.0127, -0.0044, -0.0094],\n",
      "        [-0.0171,  0.0036,  0.0092,  ...,  0.0018, -0.0247, -0.0164]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print ('Initial weights:\\n', model[0].weight)\n",
    "\n",
    "images, labels = next(iter(dataloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01) # Initialize SGD optimizer\n",
    "optimizer.zero_grad() # Clear the gradient\n",
    "\n",
    "output = model(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward() \n",
    "\n",
    "print('Gradient -', model[0].weight.grad)\n",
    "\n",
    "optimizer.step()\n",
    "print('Updated weights:\\n', model[0].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.9671714871422823\n",
      "Training loss: 0.8614217862963423\n",
      "Training loss: 0.525344142940507\n",
      "Training loss: 0.4325045504962712\n",
      "Training loss: 0.38758517825590777\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128, 64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64, 10),\n",
    "                     nn.LogSoftmax(dim=1))\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for e in range(epochs): # Loop through the whole dataset for epochs time\n",
    "    running_loss = 0\n",
    "    for images, labels in dataloader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        images = images.view(images.shape[0], -1) # Flatten the image\n",
    "        \n",
    "        optimizer.zero_grad() # Remove the culmulative gradient\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print (f'Training loss: {running_loss/len(dataloader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "images, labels = next(iter(dataloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "\n",
    "# Turn off the gradient to speed up prediction\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "    \n",
    "# Output of the network is log probability, so need to take exponential to convert to real probability\n",
    "ps = torch.exp(logps)\n",
    "view_classify(img, ps, version=\"MNIST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
